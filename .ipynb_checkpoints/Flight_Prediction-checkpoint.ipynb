{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sparkmagic in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (0.15.0)\n",
      "Requirement already satisfied: autovizwidget>=0.6 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (0.15.0)\n",
      "Requirement already satisfied: notebook>=4.2 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (6.0.3)\n",
      "Requirement already satisfied: numpy in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (1.18.1)\n",
      "Requirement already satisfied: nose in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (1.3.7)\n",
      "Requirement already satisfied: ipywidgets>5.0.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (7.5.1)\n",
      "Requirement already satisfied: pandas>=0.17.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (1.0.1)\n",
      "Requirement already satisfied: ipython>=4.0.2 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (7.12.0)\n",
      "Requirement already satisfied: tornado>=4 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (6.0.3)\n",
      "Requirement already satisfied: hdijupyterutils>=0.6 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (0.15.0)\n",
      "Requirement already satisfied: mock in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (4.0.1)\n",
      "Requirement already satisfied: requests in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (2.22.0)\n",
      "Requirement already satisfied: ipykernel in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (5.1.4)\n",
      "Requirement already satisfied: requests-kerberos>=0.8.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from sparkmagic) (0.12.0)\n",
      "Requirement already satisfied: plotly>=3 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from autovizwidget>=0.6->sparkmagic) (4.9.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (0.7.1)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (5.3.4)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (0.8.3)\n",
      "Requirement already satisfied: ipython-genutils in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (0.2.0)\n",
      "Requirement already satisfied: nbconvert in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (5.6.1)\n",
      "Requirement already satisfied: nbformat in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (5.0.4)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (18.1.1)\n",
      "Requirement already satisfied: Send2Trash in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (1.5.0)\n",
      "Requirement already satisfied: jinja2 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (2.11.1)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (4.3.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from notebook>=4.2->sparkmagic) (4.6.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipywidgets>5.0.0->sparkmagic) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.17.1->sparkmagic) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.17.1->sparkmagic) (2019.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (0.14.1)\n",
      "Requirement already satisfied: decorator in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (4.4.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (3.0.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (46.0.0.post20200309)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (0.1.0)\n",
      "Requirement already satisfied: pygments in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (2.5.2)\n",
      "Requirement already satisfied: pickleshare in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (0.7.5)\n",
      "Requirement already satisfied: backcall in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.2->sparkmagic) (0.1.0)\n",
      "Requirement already satisfied: jupyter>=1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from hdijupyterutils>=0.6->sparkmagic) (1.0.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests->sparkmagic) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests->sparkmagic) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests->sparkmagic) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests->sparkmagic) (3.0.4)\n",
      "Requirement already satisfied: cryptography>=1.3; python_version != \"3.3\" in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests-kerberos>=0.8.0->sparkmagic) (2.8)\n",
      "Requirement already satisfied: pykerberos<2.0.0,>=1.1.8; sys_platform != \"win32\" in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests-kerberos>=0.8.0->sparkmagic) (1.2.1)\n",
      "Requirement already satisfied: six in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (1.14.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (1.3.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.8.4)\n",
      "Requirement already satisfied: testpath in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (1.4.2)\n",
      "Requirement already satisfied: bleach in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (3.1.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from nbformat->notebook>=4.2->sparkmagic) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from jinja2->notebook>=4.2->sparkmagic) (1.1.1)\n",
      "Requirement already satisfied: parso>=0.5.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.2->sparkmagic) (0.5.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.2->sparkmagic) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.2->sparkmagic) (0.1.8)\n",
      "Requirement already satisfied: qtconsole in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (4.6.0)\n",
      "Requirement already satisfied: jupyter-console in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (6.1.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from cryptography>=1.3; python_version != \"3.3\"->requests-kerberos>=0.8.0->sparkmagic) (1.14.0)\n",
      "Requirement already satisfied: webencodings in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.2->sparkmagic) (0.5.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.2->sparkmagic) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.2->sparkmagic) (0.15.7)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.2->sparkmagic) (1.5.0)\n",
      "Requirement already satisfied: pycparser in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=1.3; python_version != \"3.3\"->requests-kerberos>=0.8.0->sparkmagic) (2.19)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.2->sparkmagic) (2.2.0)\n",
      "Requirement already satisfied: pymongo in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (3.10.1)\n",
      "Requirement already satisfied: mlflow in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (1.10.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (12.3.2)\n",
      "Requirement already satisfied: click>=7.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (7.0)\n",
      "Requirement already satisfied: docker>=4.0.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (4.3.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.3.0)\n",
      "Requirement already satisfied: sqlalchemy<=1.3.13 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.3.13)\n",
      "Requirement already satisfied: Flask in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.1.1)\n",
      "Requirement already satisfied: numpy in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.18.1)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (0.15.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (3.12.4)\n",
      "Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (20.0.4)\n",
      "Requirement already satisfied: alembic in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.4.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (2.8.1)\n",
      "Requirement already satisfied: sqlparse in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (0.3.1)\n",
      "Requirement already satisfied: requests>=2.17.3 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (2.22.0)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (0.11.0)\n",
      "Requirement already satisfied: querystring-parser in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: gorilla in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (0.3.0)\n",
      "Requirement already satisfied: entrypoints in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: pandas in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.0.1)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (3.1.7)\n",
      "Requirement already satisfied: pyyaml in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from mlflow) (5.3)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from azure-storage-blob>=12.0->mlflow) (2.8)\n",
      "Requirement already satisfied: msrest>=0.6.10 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from azure-storage-blob>=12.0->mlflow) (0.6.18)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.6.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from azure-storage-blob>=12.0->mlflow) (1.8.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from docker>=4.0.0->mlflow) (0.57.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (2.11.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (1.0.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from prometheus-flask-exporter->mlflow) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.0->mlflow) (46.0.0.post20200309)\n",
      "Requirement already satisfied: python-editor>=0.3 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from alembic->mlflow) (1.0.4)\n",
      "Requirement already satisfied: Mako in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from alembic->mlflow) (1.1.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from pandas->mlflow) (2019.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow) (4.0.5)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0->mlflow) (1.14.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from msrest>=0.6.10->azure-storage-blob>=12.0->mlflow) (0.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from msrest>=0.6.10->azure-storage-blob>=12.0->mlflow) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (3.0.4)\n",
      "Requirement already satisfied: pycparser in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob>=12.0->mlflow) (2.19)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/alkeshbharati/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob>=12.0->mlflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sparkmagic\n",
    "!pip install pymongo\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow import spark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.config(\"spark.jars.packages\", \"org.mlflow.mlflow-spark\").getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.shuffle.partitions', '40'),\n",
       " ('spark.files',\n",
       "  'file:///Users/alkeshbharati/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.11-2.4.2.jar,file:///Users/alkeshbharati/.ivy2/jars/org.mongodb_mongo-java-driver-3.12.5.jar'),\n",
       " ('spark.app.id', 'local-1597442978919'),\n",
       " ('spark.jars',\n",
       "  'file:///Users/alkeshbharati/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.11-2.4.2.jar,file:///Users/alkeshbharati/.ivy2/jars/org.mongodb_mongo-java-driver-3.12.5.jar'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.cores', '2'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.driver.port', '61035'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///Users/alkeshbharati/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.11-2.4.2.jar,file:///Users/alkeshbharati/.ivy2/jars/org.mongodb_mongo-java-driver-3.12.5.jar'),\n",
       " ('spark.driver.memory', '3g'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.executor.instances', '2'),\n",
       " ('spark.jars.packages', 'org.mlflow.mlflow-spark'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.default.parallelism', '40'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.executor.memory', '8g'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/Users/alkeshbharati/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.11-2.4.2.jar,/Users/alkeshbharati/.ivy2/jars/org.mongodb_mongo-java-driver-3.12.5.jar'),\n",
       " ('spark.executor.heartbeatInterval', '10000s'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.host', '10.0.0.138')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkContext.setSystemProperty('spark.executor.memory', '8g')\n",
    "SparkContext.setSystemProperty('spark.driver.memory','3g')\n",
    "SparkContext.setSystemProperty('spark.executor.heartbeatInterval','10000s')\n",
    "SparkContext.setSystemProperty('spark.default.parallelism', '40')\n",
    "SparkContext.setSystemProperty('spark.executor.cores', '2')\n",
    "SparkContext.setSystemProperty(\"spark.executor.instances\", '2')\n",
    "SparkContext.setSystemProperty(\"spark.sql.shuffle.partitions\", '40')\n",
    "\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",\"mongodb://127.0.0.1/test.flight_test\").load()\n",
    "#df.repartition(40)\n",
    "#print('partitions: ' + str(df.rdd.getNumPartitions()))\n",
    "#print(type(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.select(\"DAY_OF_MONTH\", \"DAY_OF_WEEK\", \"OP_CARRIER\", \"ORIGIN\", \"DEST\", \"DEP_DELAY\", \"ARR_DELAY\" )\n",
    "d = d.withColumn('DEP_DELAY', when(col('DEP_DELAY') == '', None).otherwise(col('DEP_DELAY')))\n",
    "d = d.withColumn('ARR_DELAY', when(col('ARR_DELAY') == '', None).otherwise(col('ARR_DELAY')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "d = d.where(col(\"DEP_DELAY\").isNotNull())\n",
    "d = d.where(col(\"ARR_DELAY\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+----------+------+----+---------+-----+\n",
      "|DAY_OF_MONTH|DAY_OF_WEEK|OP_CARRIER|ORIGIN|DEST|DEP_DELAY|label|\n",
      "+------------+-----------+----------+------+----+---------+-----+\n",
      "|           1|          3|        WN|   ONT| SJC|       -4|    0|\n",
      "|           1|          3|        WN|   ONT| SMF|       59|    1|\n",
      "|           1|          3|        WN|   ONT| SMF|       -5|    0|\n",
      "|           1|          3|        WN|   ONT| SMF|        0|    0|\n",
      "|           1|          3|        WN|   ONT| SMF|       -3|    0|\n",
      "|           1|          3|        WN|   ONT| SMF|       -5|    0|\n",
      "|           1|          3|        WN|   ONT| SMF|       -4|    0|\n",
      "|           1|          3|        WN|   ONT| SMF|        5|    0|\n",
      "|           1|          3|        WN|   ORF| BWI|       60|    1|\n",
      "|           1|          3|        WN|   ORF| BWI|       -1|    0|\n",
      "+------------+-----------+----------+------+----+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = d.select(\"DAY_OF_MONTH\", \"DAY_OF_WEEK\", \"OP_CARRIER\", \"ORIGIN\", \"DEST\", \"DEP_DELAY\", ((col(\"ARR_DELAY\") > 15).cast(\"Int\").alias(\"label\")))\n",
    "db=d.select( \"OP_CARRIER\", \"ORIGIN\", \"DEST\")\n",
    "data.show(10)\n",
    "from pyspark.sql.types import IntegerType\n",
    "data = data.withColumn(\"DEP_DELAY\", data[\"DEP_DELAY\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"label\", data[\"label\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "#train_rows = train.count()\n",
    "#test_rows = test.count()\n",
    "#print(\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+----------+---------+\n",
      "|features                                    |prediction|trueLabel|\n",
      "+--------------------------------------------+----------+---------+\n",
      "|[1.0,2.0,1.0,1.0,5.0,0.02526395173453997]   |0.0       |0        |\n",
      "|[1.0,2.0,1.0,31.0,0.0,0.02564102564102564]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,31.0,5.0,0.03506787330316742]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,31.0,6.0,0.024509803921568627] |0.0       |1        |\n",
      "|[1.0,2.0,1.0,55.0,17.0,0.027526395173453996]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,16.0,17.0,0.02526395173453997] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,62.0,3.0,0.023755656108597284] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,3.0,54.0,0.03619909502262444]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,3.0,22.0,0.026772247360482653] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,3.0,42.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,3.0,19.0,0.027149321266968326] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,3.0,86.0,0.024509803921568627] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,3.0,108.0,0.02790346907993967] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,3.0,17.0,0.032428355957767725] |0.0       |1        |\n",
      "|[1.0,2.0,1.0,11.0,3.0,0.026772247360482653] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,11.0,7.0,0.024509803921568627] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,0.0,31.0,0.08559577677224736]  |0.0       |1        |\n",
      "|[1.0,2.0,1.0,0.0,26.0,0.02526395173453997]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,0.0,3.0,0.027149321266968326]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,0.0,11.0,0.026772247360482653] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,0.0,8.0,0.03619909502262444]   |0.0       |0        |\n",
      "|[1.0,2.0,1.0,0.0,19.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,0.0,146.0,0.03205128205128205] |0.0       |1        |\n",
      "|[1.0,2.0,1.0,0.0,23.0,0.053167420814479636] |0.0       |1        |\n",
      "|[1.0,2.0,1.0,0.0,9.0,0.032428355957767725]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,0.0,13.0,0.04034690799396682]  |0.0       |1        |\n",
      "|[1.0,2.0,1.0,0.0,64.0,0.029034690799396683] |0.0       |1        |\n",
      "|[1.0,2.0,1.0,0.0,15.0,0.02790346907993967]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,0.0,15.0,0.02790346907993967]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,18.0,3.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,18.0,3.0,0.026772247360482653] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,18.0,0.0,0.026772247360482653] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,131.0,6.0,0.024132730015082957]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,103.0,6.0,0.026018099547511313]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,103.0,6.0,0.03205128205128205] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,20.0,2.0,0.02526395173453997]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,86.0,3.0,0.023755656108597284] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,86.0,0.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,29.0,0.0,0.033936651583710405] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,29.0,5.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,29.0,2.0,0.027149321266968326] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,9.0,0.0,0.027526395173453996]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,42.0,3.0,0.0392156862745098]   |0.0       |1        |\n",
      "|[1.0,2.0,1.0,149.0,0.0,0.024886877828054297]|0.0       |1        |\n",
      "|[1.0,2.0,1.0,22.0,5.0,0.027526395173453996] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,10.0,0.0,0.027149321266968326] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,10.0,0.0,0.03092006033182504]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,10.0,17.0,0.026772247360482653]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,10.0,17.0,0.033182503770739065]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,6.0,1.0,0.030542986425339366]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,6.0,0.0,0.02790346907993967]   |0.0       |0        |\n",
      "|[1.0,2.0,1.0,6.0,0.0,0.04411764705882353]   |0.0       |1        |\n",
      "|[1.0,2.0,1.0,6.0,29.0,0.02526395173453997]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,6.0,23.0,0.058446455505279035] |0.0       |1        |\n",
      "|[1.0,2.0,1.0,6.0,9.0,0.026395173453996983]  |0.0       |1        |\n",
      "|[1.0,2.0,1.0,6.0,17.0,0.0444947209653092]   |0.0       |1        |\n",
      "|[1.0,2.0,1.0,6.0,50.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,6.0,2.0,0.0667420814479638]    |0.0       |1        |\n",
      "|[1.0,2.0,1.0,6.0,15.0,0.03129713423831071]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,6.0,28.0,0.02865761689291101]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,13.0,17.0,0.026772247360482653]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,38.0,3.0,0.02564102564102564]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,7.0,3.0,0.026018099547511313]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,7.0,3.0,0.033936651583710405]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,7.0,15.0,0.02828054298642534]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,59.0,5.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,17.0,1.0,0.027149321266968326] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,17.0,3.0,0.06862745098039216]  |0.0       |1        |\n",
      "|[1.0,2.0,1.0,17.0,10.0,0.047888386123680245]|0.0       |1        |\n",
      "|[1.0,2.0,1.0,17.0,13.0,0.026018099547511313]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,17.0,2.0,0.033936651583710405] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,17.0,32.0,0.024886877828054297]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,17.0,21.0,0.029034690799396683]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,34.0,17.0,0.026018099547511313]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,44.0,6.0,0.033182503770739065] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,50.0,0.0,0.021116138763197588] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,50.0,0.0,0.0222473604826546]   |0.0       |0        |\n",
      "|[1.0,2.0,1.0,63.0,0.0,0.027149321266968326] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,63.0,6.0,0.02828054298642534]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,63.0,6.0,0.049773755656108594] |0.0       |1        |\n",
      "|[1.0,2.0,1.0,2.0,3.0,0.027149321266968326]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,2.0,20.0,0.026395173453996983] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,2.0,29.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,2.0,13.0,0.027149321266968326] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,2.0,52.0,0.027526395173453996] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,2.0,6.0,0.027526395173453996]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,2.0,14.0,0.02526395173453997]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,52.0,3.0,0.024509803921568627] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,54.0,0.024509803921568627]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,26.0,0.026395173453996983]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,3.0,0.03733031674208145]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,0.0,0.024886877828054297] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,8.0,0.027526395173453996] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,7.0,0.026018099547511313] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,6.0,0.027149321266968326] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,6.0,0.02828054298642534]  |0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,32.0,0.02790346907993967] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,14.0,14.0,0.026018099547511313]|0.0       |0        |\n",
      "|[1.0,2.0,1.0,5.0,31.0,0.024886877828054297] |0.0       |0        |\n",
      "|[1.0,2.0,1.0,5.0,31.0,0.027149321266968326] |0.0       |0        |\n",
      "+--------------------------------------------+----------+---------+\n",
      "only showing top 100 rows\n",
      "\n",
      "AUR =  0.9190386837723928\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8fefa9f12b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0maur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"AUR = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset_shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiplineModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pre-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1305\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1306\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler, VectorSlicer\n",
    "from pyspark.ml.classification import  RandomForestClassifier\n",
    "\n",
    "experiment = 'Flight_Prediction'\n",
    "#mlflow.set_tracking_uri('file:/Users/alkeshbharati/Desktop/Flight_Prediction_MLflow')\n",
    "mlflow.set_experiment(experiment)\n",
    "\n",
    "with mlflow.start_run(run_name='First-Model'):\n",
    "    encoding_var = [i[0] for i in db.dtypes if (i[1]=='string') & (i[0]!='y')]\n",
    "    string_indexes = [StringIndexer(inputCol = c, outputCol = 'IDX_' + c, handleInvalid = 'keep') for c in encoding_var]\n",
    "    #onehot_indexes = [OneHotEncoderEstimator(inputCols = ['IDX_' + c], outputCols = ['OHE_' + c]) for c in encoding_var]\n",
    "    #label_indexes = StringIndexer(inputCol = 'label', outputCol = 'label', handleInvalid = 'keep')\n",
    "    assembler = VectorAssembler(inputCols = [\"DAY_OF_MONTH\" ,\"DAY_OF_WEEK\"] + ['IDX_' + c for c in encoding_var], outputCol = \"catFeatures\")\n",
    "    catIdx = VectorIndexer(inputCol = assembler.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "    numVect = VectorAssembler(inputCols = [\"DEP_DELAY\"], outputCol=\"numFeatures\")\n",
    "    minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\n",
    "    featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")\n",
    "    lr = LogisticRegression(labelCol=\"label\",featuresCol=\"features\",maxIter=10,regParam=0.3)\n",
    "    #rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed = 8464,\n",
    "    #                            numTrees=10, cacheNodeIds = True, subsamplingRate = 0.7)\n",
    "    pipeline = Pipeline(stages= string_indexes + [ assembler, catIdx, numVect, minMax, featVect, lr])\n",
    "    piplineModel = pipeline.fit(train)\n",
    "    prediction = piplineModel.transform(test)\n",
    "    predicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "    predicted.show(100, truncate=False)\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "    aur = evaluator.evaluate(prediction)\n",
    "    print (\"AUR = \", aur)\n",
    "    mlflow.log_param(\"dataset_shape\", data.shape)\n",
    "    mlflow.log_metric(\"AUR\", aur)\n",
    "    mlflow.spark.log_model(piplineModel, \"Pre-model\")\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR2 =  0.9188037667594018\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='Final-Model'):\n",
    "    paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.1]).addGrid(lr.maxIter, [10, 5]).addGrid(lr.threshold, \n",
    "                                                                                            [0.4, 0.3]).build()\n",
    "    cv = CrossValidator(estimator=pipeline, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, \n",
    "                    numFolds=2)\n",
    "    mlflow.log_param(\"Threshold\", 0.4)\n",
    "    mlflow.log_param(\"No of Iteration\", 10)\n",
    "    mlflow.log_param(\"regularization\", 0.3)\n",
    "    model = cv.fit(train)\n",
    "    newPrediction = model.transform(test)\n",
    "    # Recalculate the Area Under ROC\n",
    "    evaluator2 = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "    aur2 = evaluator.evaluate(prediction)\n",
    "    print( \"AUR2 = \", aur2)\n",
    "    pip_model = model.bestModel\n",
    "    mlflow.spark.save_model(pip_model, \"/Users/alkeshbharati/Desktop/Flight_Prediction_MLflow\")\n",
    "    mlflow.log_metric(\"AUR\", aur2)\n",
    "    mlflow.spark.log_model(pip_model, \"Final-model\")\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
